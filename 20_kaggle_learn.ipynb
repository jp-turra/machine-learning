{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%precision 4\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Scikit-learn has another version of gradient boosting, but XGBoost has some technical advantages.\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13580.000000</td>\n",
       "      <td>1.358000e+04</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13518.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>7130.000000</td>\n",
       "      <td>8205.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.937997</td>\n",
       "      <td>1.075684e+06</td>\n",
       "      <td>10.137776</td>\n",
       "      <td>3105.301915</td>\n",
       "      <td>2.914728</td>\n",
       "      <td>1.534242</td>\n",
       "      <td>1.610075</td>\n",
       "      <td>558.416127</td>\n",
       "      <td>151.967650</td>\n",
       "      <td>1964.684217</td>\n",
       "      <td>-37.809203</td>\n",
       "      <td>144.995216</td>\n",
       "      <td>7454.417378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.955748</td>\n",
       "      <td>6.393107e+05</td>\n",
       "      <td>5.868725</td>\n",
       "      <td>90.676964</td>\n",
       "      <td>0.965921</td>\n",
       "      <td>0.691712</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>3990.669241</td>\n",
       "      <td>541.014538</td>\n",
       "      <td>37.273762</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>4378.581772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.500000e+05</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.856822</td>\n",
       "      <td>144.929600</td>\n",
       "      <td>4380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.030000e+05</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3084.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802355</td>\n",
       "      <td>145.000100</td>\n",
       "      <td>6555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058305</td>\n",
       "      <td>10331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>433014.000000</td>\n",
       "      <td>44515.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "      <td>21650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rooms         Price      Distance      Postcode      Bedroom2  \\\n",
       "count  13580.000000  1.358000e+04  13580.000000  13580.000000  13580.000000   \n",
       "mean       2.937997  1.075684e+06     10.137776   3105.301915      2.914728   \n",
       "std        0.955748  6.393107e+05      5.868725     90.676964      0.965921   \n",
       "min        1.000000  8.500000e+04      0.000000   3000.000000      0.000000   \n",
       "25%        2.000000  6.500000e+05      6.100000   3044.000000      2.000000   \n",
       "50%        3.000000  9.030000e+05      9.200000   3084.000000      3.000000   \n",
       "75%        3.000000  1.330000e+06     13.000000   3148.000000      3.000000   \n",
       "max       10.000000  9.000000e+06     48.100000   3977.000000     20.000000   \n",
       "\n",
       "           Bathroom           Car       Landsize  BuildingArea    YearBuilt  \\\n",
       "count  13580.000000  13518.000000   13580.000000   7130.000000  8205.000000   \n",
       "mean       1.534242      1.610075     558.416127    151.967650  1964.684217   \n",
       "std        0.691712      0.962634    3990.669241    541.014538    37.273762   \n",
       "min        0.000000      0.000000       0.000000      0.000000  1196.000000   \n",
       "25%        1.000000      1.000000     177.000000     93.000000  1940.000000   \n",
       "50%        1.000000      2.000000     440.000000    126.000000  1970.000000   \n",
       "75%        2.000000      2.000000     651.000000    174.000000  1999.000000   \n",
       "max        8.000000     10.000000  433014.000000  44515.000000  2018.000000   \n",
       "\n",
       "          Lattitude    Longtitude  Propertycount  \n",
       "count  13580.000000  13580.000000   13580.000000  \n",
       "mean     -37.809203    144.995216    7454.417378  \n",
       "std        0.079260      0.103916    4378.581772  \n",
       "min      -38.182550    144.431810     249.000000  \n",
       "25%      -37.856822    144.929600    4380.000000  \n",
       "50%      -37.802355    145.000100    6555.000000  \n",
       "75%      -37.756400    145.058305   10331.000000  \n",
       "max      -37.408530    145.526350   21650.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.path.join(\n",
    "    os.getcwd(), 'datasets', 'melbourne_housing', 'data.csv'\n",
    ")\n",
    "\n",
    "melbourne_data = pd.read_csv(dataset_path)\n",
    "\n",
    "melbourne_data.describe()\n",
    "# count -> mostra o número de itens não vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',\n",
       "       'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melbourne_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X_train, X_test, y_train, y_test, model=None, train=False):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute error between target and predicted values\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            random_state=0\n",
    "        )\n",
    "        train = True\n",
    "    \n",
    "    if train:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Course 1: Intro to Machine Learning\n",
    "\n",
    "https://www.kaggle.com/learn/intro-to-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing data by droping them from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna drops missing values (think of na as \"not available\")\n",
    "melbourne_data = melbourne_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.931407</td>\n",
       "      <td>1.576340</td>\n",
       "      <td>471.006940</td>\n",
       "      <td>-37.807904</td>\n",
       "      <td>144.990201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>897.449881</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.099165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.164920</td>\n",
       "      <td>144.542370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-37.855438</td>\n",
       "      <td>144.926198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>-37.802250</td>\n",
       "      <td>144.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>-37.758200</td>\n",
       "      <td>145.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>-37.457090</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rooms     Bathroom      Landsize    Lattitude   Longtitude\n",
       "count  6196.000000  6196.000000   6196.000000  6196.000000  6196.000000\n",
       "mean      2.931407     1.576340    471.006940   -37.807904   144.990201\n",
       "std       0.971079     0.711362    897.449881     0.075850     0.099165\n",
       "min       1.000000     1.000000      0.000000   -38.164920   144.542370\n",
       "25%       2.000000     1.000000    152.000000   -37.855438   144.926198\n",
       "50%       3.000000     1.000000    373.000000   -37.802250   144.995800\n",
       "75%       4.000000     2.000000    628.000000   -37.758200   145.052700\n",
       "max       8.000000     8.000000  37000.000000   -37.457090   145.526350"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = melbourne_data.Price\n",
    "\n",
    "melboune_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n",
    "X = melbourne_data[melboune_features]\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-37.8024</td>\n",
       "      <td>144.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-37.8060</td>\n",
       "      <td>144.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
       "1      2       1.0     156.0   -37.8079    144.9934\n",
       "2      3       2.0     134.0   -37.8093    144.9944\n",
       "4      4       1.0     120.0   -37.8072    144.9941\n",
       "6      3       2.0     245.0   -37.8024    144.9993\n",
       "7      2       1.0     256.0   -37.8060    144.9954"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeRegressor(\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "decision_tree_model.fit(X_train, y_train.values)\n",
    "\n",
    "predictions = decision_tree_model.predict(X_test)\n",
    "\n",
    "dt_acc = accuracy_score(y_test.values, predictions)\n",
    "dt_loss = mean_absolute_error(y_test.values, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(X_train, y_train)\n",
    "melb_preds = forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Error: 266553.3637096774\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree\")\n",
    "print(f\"Error: {dt_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Error:  201129.4307089094\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest\")\n",
    "print(\"Error: \", mean_absolute_error(y_test, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Course 2: Intermidiate Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "Machine learn models are not capable to handle missing values. Instead we need to deal with them by:\n",
    "\n",
    "1. Droping Columns with missing values\n",
    "2. Imputing missing values (Fill missing values)\n",
    "3. Both imputing missing values and creating a new column to mark them as missing.\n",
    "    * ![image.png](./resources/ImputingExtended.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the target data\n",
    "y = melbourne_data.Price\n",
    "\n",
    "# Getting the rest of the dataset as input\n",
    "X = melbourne_data.drop(['Price'], axis=1)\n",
    "# Keeping things simple by taking only numerical values\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: ['Car', 'BuildingArea', 'YearBuilt']\n"
     ]
    }
   ],
   "source": [
    "# Getting columns with missing values\n",
    "# It returns 'col' if 'col' has any missing values in 'X_train'\n",
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "print(f\"Columns with missing values: {cols_with_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 -> Dropping columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with dropped columns: 183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "X_train_reduced = X_train.drop(cols_with_missing, axis=1)\n",
    "X_test_reduced = X_test.drop(cols_with_missing, axis=1)\n",
    "\n",
    "score_dropped = score_dataset(X_train_reduced, X_test_reduced, y_train, y_test)\n",
    "print(f\"Error with dropped columns: {score_dropped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 -> Imputing missing values\n",
    "\n",
    "* We will do this by putting in the mean value of the column. It's a simple way that have shown good results. It may not be the best way to impute missing values, but it's a good start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with imputed columns: 178166.46269899711\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer()\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "score_imputed = score_dataset(X_train_imputed, X_test_imputed, y_train, y_test)\n",
    "print(f\"Error with imputed columns: {score_imputed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 -> Imputing missing values and creating a new column to mark them as missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with imputed columns: 178927.503183954\n"
     ]
    }
   ],
   "source": [
    "# Make a copy to avoid overwriting original data (when imputing)\n",
    "X_train_plus = X_train.copy()\n",
    "X_test_plus = X_test.copy()\n",
    "\n",
    "# Creating new column to make whether or not there was missing data\n",
    "for col in cols_with_missing:\n",
    "    # X_*_plus[col].isnull() return an array os booleans indicating if each position is missing or not\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_test_plus[col + '_was_missing'] = X_test_plus[col].isnull()\n",
    "\n",
    "# Imputing data\n",
    "imputer = SimpleImputer()\n",
    "X_train_plus_imputed = imputer.fit_transform(X_train_plus)\n",
    "X_test_plus_imputed = imputer.transform(X_test_plus)\n",
    "\n",
    "# Scoring model\n",
    "score_plus_imputed = score_dataset(X_train_plus_imputed, X_test_plus_imputed, y_train, y_test)\n",
    "print(f\"Error with imputed columns: {score_plus_imputed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data\n",
    "\n",
    "* To be considered categorical data, a feature must be part of a fixed set of categories. For example, in a survey about cars, people will answare \"Honda\", \"Ford\" or \"Dodge\". In this case, the variable would be considered categorical data.\n",
    "\n",
    "* Three approaches to deal with this kind of data:\n",
    "1. Drop Categorical Variables\n",
    "2. Ordinal Encoder (0, 1, 2, 3, ...)\n",
    "3. One Hot Encoder [[0, 0, 1], [0, 1, 0], [1, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = melbourne_data.Price\n",
    "X = melbourne_data.drop(['Price'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "# Dropping missing values as it's not the focus of this section\n",
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "X_train.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and \n",
    "                        X_train[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train_filtred = X_train[my_cols].copy()\n",
    "X_test_filtred = X_test[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "\n",
       "       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n",
       "12167       1.0       0.0  -37.85984    144.9867        13240.0  \n",
       "6524        2.0     193.0  -37.85800    144.9005         6380.0  \n",
       "8413        1.0     555.0  -37.79880    144.8220         3755.0  \n",
       "2919        1.0     265.0  -37.70830    144.9158         8870.0  \n",
       "6043        1.0     673.0  -37.76230    144.8272         4217.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filtred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorival columns\n",
    "s = (X_train_filtred.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping categorical variables MAE: 183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "X_train_dropped = X_train_filtred.drop(object_cols, axis=1)\n",
    "X_test_dropped = X_test_filtred.drop(object_cols, axis=1)\n",
    "\n",
    "score_dropped_cat = score_dataset(X_train_dropped, X_test_dropped, y_train, y_test)\n",
    "print(f\"After dropping categorical variables MAE: {score_dropped_cat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with Ordinal Encoder: 175062.2967599411\n"
     ]
    }
   ],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "X_train_encoded = X_train_filtred.copy()\n",
    "X_test_encoded = X_test_filtred.copy()\n",
    "\n",
    "X_train_encoded[object_cols] = ordinal_encoder.fit_transform(X_train_filtred[object_cols])\n",
    "X_test_encoded[object_cols] = ordinal_encoder.transform(X_test_filtred[object_cols])\n",
    "\n",
    "score_encoded = score_dataset(X_train_encoded, X_test_encoded, y_train, y_test)\n",
    "print(f\"MAE with Ordinal Encoder: {score_encoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with One Hot Encoder: 176703.63810751104\n"
     ]
    }
   ],
   "source": [
    "# Handle_unknown -> avoid errors when the validation data contains classes that aren't represented in the training data\n",
    "# sparse -> ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix).\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "one_hot_cols_train = pd.DataFrame(one_hot_encoder.fit_transform(X_train_filtred[object_cols]))\n",
    "one_hot_cols_test = pd.DataFrame(one_hot_encoder.transform(X_test_filtred[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "one_hot_cols_train.index = X_train_filtred.index\n",
    "one_hot_cols_test.index = X_test_filtred.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train_filtred.drop(object_cols, axis=1)\n",
    "num_X_test = X_test_filtred.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "one_hot_X_train = pd.concat([num_X_train, one_hot_cols_train], axis=1)\n",
    "one_hot_X_test = pd.concat([num_X_test, one_hot_cols_test], axis=1)\n",
    "\n",
    "# Ensure all columns have string type\n",
    "one_hot_X_train.columns = one_hot_X_train.columns.astype(str)\n",
    "one_hot_X_test.columns = one_hot_X_test.columns.astype(str)\n",
    "\n",
    "score_onehot = score_dataset(one_hot_X_train, one_hot_X_test, y_train, y_test)\n",
    "print(f\"MAE with One Hot Encoder: {score_onehot}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "* A way to organize preprocessing with modeling code organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = melbourne_data.drop(labels=[\"Price\"], axis=1)\n",
    "y = melbourne_data.Price\n",
    "\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "\n",
       "       Bathroom  Car  Landsize  BuildingArea  YearBuilt  Lattitude  \\\n",
       "12167       1.0  1.0       0.0           NaN     1940.0  -37.85984   \n",
       "6524        2.0  1.0     193.0           NaN        NaN  -37.85800   \n",
       "8413        1.0  1.0     555.0           NaN        NaN  -37.79880   \n",
       "2919        1.0  1.0     265.0           NaN     1995.0  -37.70830   \n",
       "6043        1.0  2.0     673.0         673.0     1970.0  -37.76230   \n",
       "\n",
       "       Longtitude  Propertycount  \n",
       "12167    144.9867        13240.0  \n",
       "6524     144.9005         6380.0  \n",
       "8413     144.8220         3755.0  \n",
       "2919     144.9158         8870.0  \n",
       "6043     144.8272         4217.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Define Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create and Evaluate Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing preprocessor, total=   0.0s\n",
      "[Pipeline] ............. (step 2 of 2) Processing model, total=   5.2s\n",
      "MAE: 160679.18917034855\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "predictions = pipeline.predict(X_valid)\n",
    "\n",
    "score = mean_absolute_error(y_valid, predictions)\n",
    "print(f\"MAE: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preprocessor',\n",
       "  ColumnTransformer(transformers=[('num', SimpleImputer(strategy='constant'),\n",
       "                                   ['Rooms', 'Distance', 'Postcode', 'Bedroom2',\n",
       "                                    'Bathroom', 'Car', 'Landsize', 'BuildingArea',\n",
       "                                    'YearBuilt', 'Lattitude', 'Longtitude',\n",
       "                                    'Propertycount']),\n",
       "                                  ('cat',\n",
       "                                   Pipeline(steps=[('imputer',\n",
       "                                                    SimpleImputer(strategy='most_frequent')),\n",
       "                                                   ('onehot',\n",
       "                                                    OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                  sparse_output=False))]),\n",
       "                                   ['Type', 'Method', 'Regionname'])])),\n",
       " ('model', RandomForestRegressor(random_state=0))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "* Runs da modeling process on different subsets of the data, in order to get multiple measures of the modely quality.\n",
    "* This avoids the problem of taking noise into account.\n",
    "\n",
    "### When to use cross-validation\n",
    "\n",
    "* For small datasets, where extra computational burden isn't a big deal, you should run cross-validation.\n",
    "* For larger datasets, a single validation set is sufficient.\n",
    "* There's no simple threshold for what constitutes a large vs. small dataset. But if your model takes a couple minutes or less to run, it's probably worth switching to cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE scores:\n",
      " [301628.7893587  303164.4782723  287298.331666   236061.84754543\n",
      " 260383.45111427]\n"
     ]
    }
   ],
   "source": [
    "# Select subset of predictors\n",
    "cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
    "\n",
    "X = melbourne_data[cols_to_use]\n",
    "y = melbourne_data.Price\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', SimpleImputer()),\n",
    "        ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "num_gropus = 5\n",
    "scores = -1 * cross_val_score(pipeline, X, y,\n",
    "                              cv=num_gropus,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score (across experiments):\n",
      "277707.3795913405\n"
     ]
    }
   ],
   "source": [
    "print(\"Average MAE score (across experiments):\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "* https://en.wikipedia.org/wiki/Hyperparameter_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 35 candidates, totalling 105 fits\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=100, preprocessor__strategy=mean; total time=   1.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=100, preprocessor__strategy=mean; total time=   1.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=200, preprocessor__strategy=mean; total time=   3.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=200, preprocessor__strategy=mean; total time=   3.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=200, preprocessor__strategy=mean; total time=   3.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=400, preprocessor__strategy=mean; total time=   9.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=500, preprocessor__strategy=mean; total time=   9.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=None, model__n_estimators=500, preprocessor__strategy=mean; total time=   9.8s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=100, preprocessor__strategy=mean; total time=   1.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=100, preprocessor__strategy=mean; total time=   1.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=100, preprocessor__strategy=mean; total time=   1.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=200, preprocessor__strategy=mean; total time=   2.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=200, preprocessor__strategy=mean; total time=   2.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=200, preprocessor__strategy=mean; total time=   2.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=300, preprocessor__strategy=mean; total time=   3.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=300, preprocessor__strategy=mean; total time=   3.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=300, preprocessor__strategy=mean; total time=   3.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=400, preprocessor__strategy=mean; total time=   4.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=400, preprocessor__strategy=mean; total time=   4.6s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=400, preprocessor__strategy=mean; total time=   4.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=500, preprocessor__strategy=mean; total time=   5.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=500, preprocessor__strategy=mean; total time=   5.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=10, model__n_estimators=500, preprocessor__strategy=mean; total time=   5.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=100, preprocessor__strategy=mean; total time=   1.7s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=100, preprocessor__strategy=mean; total time=   1.8s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=100, preprocessor__strategy=mean; total time=   1.7s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=200, preprocessor__strategy=mean; total time=   3.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=200, preprocessor__strategy=mean; total time=   3.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=300, preprocessor__strategy=mean; total time=   5.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=300, preprocessor__strategy=mean; total time=   5.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=300, preprocessor__strategy=mean; total time=   5.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=400, preprocessor__strategy=mean; total time=   6.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=400, preprocessor__strategy=mean; total time=   7.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=400, preprocessor__strategy=mean; total time=   7.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=500, preprocessor__strategy=mean; total time=   9.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=500, preprocessor__strategy=mean; total time=   9.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=16, model__n_estimators=500, preprocessor__strategy=mean; total time=   8.7s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.6s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.7s\n",
      "[CV] END model__criterion=poisson, model__max_depth=32, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=500, preprocessor__strategy=mean; total time=  11.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=500, preprocessor__strategy=mean; total time=  14.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=64, model__n_estimators=500, preprocessor__strategy=mean; total time=  12.6s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=100, preprocessor__strategy=mean; total time=   3.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.2s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=300, preprocessor__strategy=mean; total time=   7.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=300, preprocessor__strategy=mean; total time=   7.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.7s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.9s\n",
      "[CV] END model__criterion=poisson, model__max_depth=128, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=100, preprocessor__strategy=mean; total time=   2.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=200, preprocessor__strategy=mean; total time=   4.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.5s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=300, preprocessor__strategy=mean; total time=   6.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.4s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=400, preprocessor__strategy=mean; total time=   8.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=400, preprocessor__strategy=mean; total time=   9.0s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.3s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=500, preprocessor__strategy=mean; total time=  10.1s\n",
      "[CV] END model__criterion=poisson, model__max_depth=256, model__n_estimators=500, preprocessor__strategy=mean; total time=   9.9s\n",
      "Best parameter (CV score=-281912.148):\n",
      "model__criterion poisson\n",
      "model__max_depth 10\n",
      "model__n_estimators 500\n",
      "preprocessor__strategy mean\n"
     ]
    }
   ],
   "source": [
    "def create_pipeline():\n",
    "    return Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', SimpleImputer()),\n",
    "            ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"model__criterion\": [\"poisson\"],\n",
    "    \"model__max_depth\": [None, 10, 16, 32, 64, 128, 256],\n",
    "    \"preprocessor__strategy\": [\"mean\"]\n",
    "}\n",
    "\n",
    "num_gropus = 3\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=create_pipeline(),\n",
    "    param_grid=param_grid,\n",
    "    cv=num_gropus,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid_search.best_score_)\n",
    "for param in grid_search.best_params_:\n",
    "    print(param, grid_search.best_params_[param])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Library - Extreme Gradient Boosting\n",
    "\n",
    "* The most accurate modeling technique for structured data.\n",
    "\n",
    "### Gradient Booting\n",
    "\n",
    "* Gradient boosting is a method that goes through cycles to iteratively add models into an ensemble.\n",
    "![image.png](./resources/gradientBoosting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
    "\n",
    "X = melbourne_data[cols_to_use]\n",
    "y = melbourne_data.Price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 239806.40413119018\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "score = mean_absolute_error(y_test, predictions)\n",
    "print(f\"MAE: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tunning\n",
    "\n",
    "* n_estimators: It is equal to the number of models that we include in the ensemble.\n",
    "    * Too low a value causes underfitting\n",
    "    * Too high a value causes overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 251012.18044631352\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "score = mean_absolute_error(y_test, predictions)\n",
    "print(f\"MAE: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* early_stopping_rounds:  Early stopping causes the model to stop iterating when the validation score stops improving\n",
    "    *  We stop after 5 straight rounds of deteriorating validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 242594.4020825663\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=500, early_stopping_rounds=5)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "score = mean_absolute_error(y_test, predictions)\n",
    "print(f\"MAE: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* learning_rate: \n",
    "    * Instead of getting predictions by simply adding up the predictions from each component model, we can multiply the predictions from each model by a small number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 238429.98981038292\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=500, early_stopping_rounds=5, learning_rate=0.05)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "score = mean_absolute_error(y_test, predictions)\n",
    "print(f\"MAE: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* n_jobs: \n",
    "    * On larger datasets where runtime is a consideration, you can use parallelism to build your models faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 238429.98981038292\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=500, early_stopping_rounds=5, learning_rate=0.05, n_jobs=2)\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "score = mean_absolute_error(y_test, predictions)\n",
    "print(f\"MAE: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Leakage\n",
    "\n",
    "* Happens when your training data contains information about the target, but similar data will not be available when the model is used for prediction. This leads to high performance on the training set (and possibly even the validation data), but the model will perform poorly in production.\n",
    "\n",
    "### Target Leakage\n",
    "\n",
    "* Occurs when your predictors include data that will not be available at the time you make predictions.\n",
    "* To prevent this type of data leakage, any variable updated (or created) after the target value is realized should be excluded.\n",
    "\n",
    "\n",
    "### Train-Test Leakage\n",
    "\n",
    "* A different type of leak occurs when you aren't careful to distinguish training data from validation data.\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
